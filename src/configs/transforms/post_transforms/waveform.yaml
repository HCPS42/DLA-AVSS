train:
  mix_wav: ${transforms._upsample}
  speaker_1_wav: ${transforms._upsample}
  speaker_2_wav: ${transforms._upsample}
  output_wav:
    _target_: torch.nn.Sequential
    _args_:
      - ${transforms._upsample}
      - _target_: src.transforms.NormalizeAudio
inference:
  mix_wav: ${transforms._upsample}
  speaker_1_wav: ${transforms._upsample}
  speaker_2_wav: ${transforms._upsample}
  output_wav:
    _target_: torch.nn.Sequential
    _args_:
      - ${transforms._upsample}
      - _target_: src.transforms.NormalizeAudio
